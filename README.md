<div align="center">

<img src="assets/banner.svg" alt="RAG System Banner" width="900"/>

[![Python](https://img.shields.io/badge/Python-3.9%2B-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://www.python.org/)
[![LangChain](https://img.shields.io/badge/LangChain-Latest-1C3C3C?style=for-the-badge&logo=chainlink&logoColor=white)](https://langchain.com/)
[![Gemini](https://img.shields.io/badge/Google%20Gemini-Flash-4285F4?style=for-the-badge&logo=google&logoColor=white)](https://ai.google.dev/)
[![Gradio](https://img.shields.io/badge/Gradio-UI-FF7C00?style=for-the-badge&logo=gradio&logoColor=white)](https://gradio.app/)
[![ChromaDB](https://img.shields.io/badge/ChromaDB-VectorStore-6C3EEB?style=for-the-badge)](https://www.trychroma.com/)
[![HuggingFace](https://img.shields.io/badge/HuggingFace-Embeddings-FFD21E?style=for-the-badge&logo=huggingface&logoColor=black)](https://huggingface.co/)
[![License](https://img.shields.io/badge/License-MIT-22C55E?style=for-the-badge)](LICENSE)

*Chat with your documents using state-of-the-art AI â€” multi-thread support, Self-RAG, hybrid retrieval, and semantic caching.*

[Features](#-features) â€¢ [How It Works](#-how-it-works) â€¢ [Demo](#-demo) â€¢ [Installation](#-installation) â€¢ [Usage](#-usage) â€¢ [Architecture](#-architecture) â€¢ [Configuration](#-configuration)

</div>

---

## ğŸ“Œ Overview

**Ultimate RAG System** is a fully-featured, multi-threaded document Q&A application powered by **Google Gemini**, **LangChain**, and **ChromaDB**. Upload PDFs, Word documents, or text files and have intelligent, context-aware conversations about their contents â€” all through a clean **Gradio** web interface.

What sets it apart is a deeply engineered **7-step retrieval pipeline**: stacking BM25 keyword search, dense vector search, FlashRank neural reranking, Self-RAG answer verification, and semantic query caching â€” all cooperating to deliver fast, accurate, grounded responses.

---

## ğŸŒ System Architecture

<img src="assets/architecture.svg" alt="System Architecture" width="900"/>

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ—‚ï¸ **Multi-Thread Management** | Isolated threads â€” each with its own documents, vector store, and chat history |
| ğŸ”€ **Hybrid Retrieval** | BM25 + Dense vector search with fully configurable weight blending |
| ğŸ† **Neural Reranking** | FlashRank (ms-marco-MiniLM-L-12-v2) reorders results for precision |
| ğŸ§  **Self-RAG** | LLM self-evaluates query complexity and verifies answer quality |
| âš¡ **Semantic Cache** | Cosine-similarity cache avoids redundant LLM calls (threshold 0.85) |
| ğŸªµ **Hierarchical Chunking** | Parent/child chunk architecture for precision + rich context |
| ğŸ“„ **Multi-Format Ingestion** | PDF, DOCX, DOC, TXT all fully supported |
| ğŸ“Š **Query Analytics** | Per-thread logs with response times, chunk counts, cache hit rates |
| ğŸ” **Auto-Retry** | Exponential backoff handles API quota errors gracefully |

---

## ğŸ”„ How It Works

### Phase 1 â€” Document Ingestion

```
RAW FILE  (PDF / DOCX / TXT)
    â”‚
    â–¼
DOCUMENT LOADER  â”€â”€â”€â”€â”€  extracts text + page metadata
    â”‚
    â–¼
DOCUMENT ANALYZER
   â”œâ”€ Section detection:  Abstract Â· Intro Â· Methods Â· Results Â· Conclusion
   â”œâ”€ Key term extraction:  word frequency analysis
   â””â”€ Visual flag:  Figure Â· Table Â· Algorithm
    â”‚
    â”œâ”€â”€â”€â”€ Flat Chunking â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Hierarchical Chunking
    â”‚     (precise / balanced / contextual)   (parent 2000t â†’ child 500t)
    â”‚
    â–¼
HuggingFace Embeddings  â†’  ChromaDB Vector Store
```

### Phase 2 â€” Query & Retrieval Pipeline

<img src="assets/pipeline.svg" alt="Query and Retrieval Pipeline" width="900"/>

---

## ğŸ¬ Demo

<img src="assets/demo.svg" alt="Terminal Demo" width="900"/>

---

## ğŸªµ Chunking Strategies

<img src="assets/chunking.svg" alt="Chunking Strategy Comparison" width="900"/>

---

## ğŸ” Retrieval Strategy Weights

<img src="assets/retrieval.svg" alt="Retrieval Strategy Weight Balance" width="900"/>

---

## ğŸ¤– Embedding Models

<img src="assets/embeddings.svg" alt="Embedding Model Comparison" width="900"/>

---

## ğŸ§µ Thread Isolation

<img src="assets/threads.svg" alt="Thread Isolation Model" width="900"/>

---

## ğŸ—ï¸ Architecture

### Class Map

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          CLASS RELATIONSHIPS                             â”‚
â”‚                                                                          â”‚
â”‚  RAGConfig â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  (strategy params)                                                   â”‚  â”‚
â”‚                                                                      â–¼  â”‚
â”‚  SemanticCache â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º UltimateRAGSystem â—„â”€â”€ ThreadData â”‚
â”‚  (cosine-sim cache)                   (orchestrator)       (per-thread) â”‚
â”‚                                              â”‚                          â”‚
â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚                          â–¼                   â–¼              â–¼           â”‚
â”‚                   AdvancedRetriever       SelfRAG    DocumentAnalyzer   â”‚
â”‚                   â”œâ”€ create_hyde()        â”œâ”€ analyze_query()            â”‚
â”‚                   â”œâ”€ create_multi_q()     â””â”€ verify_answer()            â”‚
â”‚                   â”œâ”€ create_ensemble()                                  â”‚
â”‚                   â””â”€ create_compress()                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### File Structure

```
ultimate-rag-system/
â”‚
â”œâ”€â”€ ğŸ“„ app.py                     â† Entire application
â”‚   â”œâ”€â”€ ğŸ”§ RAGConfig                â† Strategy parameters & constants
â”‚   â”œâ”€â”€ âš¡ SemanticCache             â† Cosine-similarity query cache
â”‚   â”œâ”€â”€ ğŸ“¦ ThreadData               â† Per-thread isolated state
â”‚   â”œâ”€â”€ ğŸ”¬ DocumentAnalyzer         â† Metadata & structure extraction
â”‚   â”œâ”€â”€ ğŸ” AdvancedRetriever        â† HyDE, MultiQuery, Ensemble, Rerank
â”‚   â”œâ”€â”€ ğŸ§  SelfRAG                  â† Query analysis & answer verification
â”‚   â””â”€â”€ ğŸ¯ UltimateRAGSystem        â† Core orchestrator + Gradio UI
â”‚
â”œâ”€â”€ ğŸ—„ï¸  chroma_db_threads/           â† Auto-created at runtime
â”‚   â””â”€â”€ {thread-uuid}/              â† Isolated vector store per thread
â”‚
â”œâ”€â”€ ğŸ” .env                         â† API keys (never commit this)
â”œâ”€â”€ ğŸ“‹ requirements.txt
â””â”€â”€ ğŸ“– README.md
```

---

## ğŸ› ï¸ Installation

**Prerequisites:** Python 3.9+ Â· [Google Gemini API Key](https://ai.google.dev/)

```bash
# 1 â€” Clone
git clone https://github.com/ZeyadArafa/ultimate-rag-system.git
cd ultimate-rag-system

# 2 â€” Virtual environment
python -m venv venv
source venv/bin/activate          # Windows: venv\Scripts\activate

# 3 â€” Dependencies
pip install -r requirements.txt

# 4 â€” API key
echo "GOOGLE_API_KEY=your_key_here" > .env

# 5 â€” Run
python app.py
# Open â†’ http://localhost:7860
```

---

## ğŸ“¦ Requirements

```txt
gradio
langchain
langchain-google-genai
langchain-huggingface
langchain-community
langchain-text-splitters
langchain-core
langchain-classic
chromadb
flashrank
rank-bm25
sentence-transformers
pypdf
unstructured[docx]
python-dotenv
numpy
```

---

## ğŸš€ Usage Guide

**â‘  Create a Thread** â€” Name it and isolate your context. Each thread has its own documents and memory.

**â‘¡ Upload a Document** â€” Pick chunking strategy and embedding model, then drop in your PDF/DOCX/TXT.

**â‘¢ Configure Retrieval** â€” Choose retrieval strategy (`hybrid` recommended), toggle Self-RAG and Semantic Cache.

**â‘£ Chat** â€” Ask anything in natural language. History is preserved and resolved across turns.

### ğŸ’¡ Strategy Decision Guide

| Goal | Chunking | Retrieval | Self-RAG | Cache |
|------|----------|-----------|----------|-------|
| ğŸ“° Research papers | `hierarchical` | `hybrid` | âœ… ON | âœ… ON |
| ğŸ” Quick fact lookup | `precise` | `keyword` | âŒ OFF | âœ… ON |
| âš¡ Maximum speed | `precise` | `hybrid` | âŒ OFF | âœ… ON |
| ğŸŒ Multilingual docs | `balanced` | `semantic` | âœ… ON | âŒ OFF |
| ğŸ“Š Complex analysis | `contextual` | `semantic` | âœ… ON | âŒ OFF |
| ğŸ“š Multi-doc topics | `balanced` | `hybrid` | âœ… ON | âœ… ON |

---

## âš™ï¸ Configuration

```python
class RAGConfig:
    CHUNK_STRATEGIES = {
        "balanced":     {"size": 700,  "overlap": 120},
        "precise":      {"size": 400,  "overlap": 80},
        "contextual":   {"size": 1200, "overlap": 200},
        "hierarchical": {"parent_size": 2000, "child_size": 500, "overlap": 100}
    }
    RETRIEVAL_STRATEGIES = {
        "hybrid":   {"bm25_weight": 0.5, "vector_weight": 0.5},
        "semantic": {"bm25_weight": 0.3, "vector_weight": 0.7},
        "keyword":  {"bm25_weight": 0.7, "vector_weight": 0.3}
    }
    EMBEDDING_MODELS = {
        "fast":         "all-MiniLM-L6-v2",
        "balanced":     "sentence-transformers/all-mpnet-base-v2",
        "multilingual": "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    }
    API_RETRY_DELAY = 2
    MAX_API_RETRIES = 3
```

---

## ğŸ”§ Troubleshooting

| Symptom | Solution |
|---------|----------|
| ğŸŒ Slow responses | Use `fast` embedding Â· disable Self-RAG |
| ğŸ¯ Irrelevant answers | Switch to `semantic` retrieval |
| ğŸ” Missing detail | Use `contextual` chunking |
| âš ï¸ API quota errors | System auto-retries with exponential backoff |
| ğŸ§µ Thread confusion | Check active thread before uploading |
| ğŸ”‘ API key not found | Ensure `.env` exists with `GOOGLE_API_KEY` set |
| ğŸ’¾ ChromaDB error | Check write permissions on `./chroma_db_*` |
| ğŸ“„ Unsupported format | Only PDF, DOCX, DOC, TXT are supported |

---

## ğŸ¤ Contributing

```bash
git checkout -b feature/your-feature
git commit -m "feat: describe your change"
git push origin feature/your-feature
# â†’ Open a Pull Request
```

---

## ğŸ“„ License

MIT â€” see [LICENSE](LICENSE).

---

## ğŸ™ Acknowledgements

| Library | Role |
|---------|------|
| [LangChain](https://langchain.com/) | RAG pipeline framework |
| [Google Gemini](https://ai.google.dev/) | LLM backbone |
| [ChromaDB](https://www.trychroma.com/) | Vector store |
| [FlashRank](https://github.com/PrithivirajDamodaran/FlashRank) | Neural reranking |
| [HuggingFace](https://huggingface.co/) | Embedding models |
| [Gradio](https://gradio.app/) | Web interface |

---

<div align="center">

**â­ If this project helped you, a star goes a long way!**

Made with â¤ï¸ and a lot of â˜•

</div>